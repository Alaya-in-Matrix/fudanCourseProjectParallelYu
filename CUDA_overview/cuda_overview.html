<!DOCTYPE html>
<html>
<head>
<title>cuda_overview</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}


/* code */
pre, code, tt {
  font-size: 14px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}
/*
code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  //border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  //border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  //border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}
*/
/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}

</style>
<head>
	<meta charset="utf-8">

	<link rel="stylesheet" href="decorateMarkdown/highlight/styles/molokai.css">

	<script src="decorateMarkdown/jquery-2.1.1.min.js"></script>
	<script>
	$(function(){
    	var styleHref = $("#markdowncodestyle").val();
    	if(styleHref){
    		styleHref="decorateMarkdown/highlight/styles/"+styleHref+".css";
    		$("#markdowncodestyle").hide();
    		$("head").append($("<link href='"+	styleHref +"' type='text/css' rel='stylesheet'>"));
    	}
	});
	</script>
	<script src="decorateMarkdown/highlight/highlight.pack.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>

</head>
</head>
<body>
<h1 id="cuda-">CUDA编程模型综述</h1>
<ul>
<li>吕文龙</li>
<li>14210720082</li>
</ul>
<h2 id="-">摘要</h2>
<p>介绍了通用GPU编程以及CUDA出现的背景, CUDA C语言语法以及CUDA在GPU上的执行模型. 介绍了最新版本CUDA的一些特性以及基于CUDA的并行计算扩展thrust库. 介绍了用于profile CUDA程序的工具. 并以一个蒙特卡洛算法为例, 展示了GPU编程的加速比.</p>
<h2 id="-gpu-gpgpu-cuda">背景介绍: GPU, GPGPU 与 CUDA</h2>
<h3 id="gpu-cpu-">GPU 与 CPU 特性对比</h3>
<p>GPU最初是作为CPU的协处理器, 为了加速图形计算而设计的. 图形计算要求对大量像素点的重复高密度计算, 此种需求造成了CPU与GPU在设计时侧重点的差异. </p>
<p>GPU相对CPU主要有以下三点优势:</p>
<ul>
<li>更强的浮点数计算能力(与之对应的是更弱的逻辑控制功能)</li>
<li>更大的内存带宽</li>
<li>轻量级的线程切换</li>
</ul>
<p>具体而言, 相比GPU, CPU需要处理更加通用的, 普适性的任务. 因而在设计时, CPU更侧重于逻辑操作, 会将大量的硬件用于控制逻辑以及缓存, 而GPU则更侧重高密度的浮点数运算. 因此在硬件设计上, 会更倾向于添加大量并行的运算单元,下图为CPU与GPU的硬件组成对比图: </p>
<center><img style='margin:20px' src="./image/CPU_GPU_hardware_cmp.png"></center><br>设计上的差异, 使得在浮点数处理方面, 同时代的GPU往往远胜CPU, 下图为CPU-GPU的浮点数处理能力(GFLOPS)对比:<br><center><img width=400 style='margin:20px' src="./image/GPU_CPU_FLOPS.png"></center><br>下图为不同时代CPU与GPU的内存带宽对比:<br><center><img width=400 style='margin:20px' src="./image/CPU_GPU_MEM_BANDWIDTH.png"></center>

<p>CPU的一个核心(或者通过超线程技术虚拟将一个核心虚拟成的多个核心). 同一时刻通常只能运行一个线程的指令, 当线程数超过核心数时, 多个核心共享计算资源, 而当进行线程切换时, 必须要花费大量的clock cycle来保存上下文. </p>
<p>而GPU上具有大量的核心, 并且能够通过硬件来管理线程, 可以实现零开销的线程切换. 当一个线程因为访存或者线程同步而等待时, 可以在下一个时钟周期立刻切换到准备计算的线程. </p>
<p>目前的GPU上没有很复杂的缓存机制, 也没有为单个计算单元设计复杂的流水线等指令级并行机制(至少目前为止这一点仍然是成立的, 不过随着GPU应用领域不再局限于图形处理方面而转向各种通用计算领域, GPU上应该也会出现强大的缓存与 Instruction level parallism 机制). 它主要通过零开销的线程切换来隐藏延迟. 正式由于这个特性, 在后面测试的例子中可以看到, 要使GPU达到加速比, GPU上同时运行的线程应该是数倍于GPU的计算单元(SP).</p>
<h3 id="-gpgpu-cuda">从 GPGPU 到 CUDA</h3>
<p>随着GPU性能与可编程性的不断提高, GPU开始被用于图形处理之外的通用领域, 通过CPU+GPU异构编程的方式来进行并行计算, 即CPU负责控制逻辑, 而将大规模的数据计算交给GPU来处理. 使用GPU来进行数据并行的运算, 能够极大的提高性能/功耗比. <a href="http://www.green500.org/">Green500</a>网站公布的绿色超级计算机排名中, 性能-功耗比排名考前的超级计算机中, 大多都使用了GPU作为协处理器进行加速, 下图为2014年11月公布的最新绿色超级计算机前十位, 其中, 第一名使用了AMD的GPU进行加速, 3-10都使用了NVIDIA的GPU进行加速:</p>
<center><img width=640 style='margin:20px' src="./image/GREEN500_TOP10.png"></center>

<p>GPGPU使得GPU的应用不再局限于图形处理领域, 但是, 最早的GPGPU开发需要直接使用图形学API, 要求编程人员将数据打包成纹理, 将计算任务映射为对纹理的渲染过程, 这种方式要求程序员对图形学硬件与编程接口有深入了解, 开发难度很大. </p>
<p>2007年,NVIDIA推出了CUDA(Compute Unified Device Architecture, 统一计算设备架构). CUDA不需要借助图形学API, 并采用了类C语言进行开发. 开发者能够从熟悉的C语言比较平稳的从CPU过渡到GPU, 而不必重新学习语法. </p>
<p>同时, 与以往的GPU相比, 支持CUDA的GPU在架构上有了显著的改进, 使得CUDA架构更加适用于GPU通用计算. 例如, 引入了片内共享存储器, 使得线程间可以通过共享存储器进行通信.</p>
<p>CUDA只支持NVIDIA公司的GPU, 目前, 最新的CUDA的版本号为6.5</p>
<h2 id="cuda-">CUDA 编程模型</h2>
<h3 id="-">主机端与设备端</h3>
<p>CUDA为CPU-GPU异构编程, 程序的执行环境分为主机端(host)与设备端(device), 主机端即CPU, 设备端即GPU. 程序由主机端的main函数开始, 从主机端调用设备端的程序. 一个系统中, 可以有一个主机和多个设备. 主机与设备端拥有各自独立的存储器(内存与显存). </p>
<p>CUDA通过扩展的C语法编写程序, 支持三种函数, <code>host</code>函数,<code>global</code>函数与<code>device</code>函数. 函数默认为host函数, 即CPU上运行的代码, 这部分程序经由CUDA识别后, 交给传统的C编译器如<code>gcc</code>进行编译, 而<code>global</code>函数和<code>device</code>函数是运行在GPU上的程序, <code>global</code>为CPU调用的GPU函数, 而<code>device</code>函数则为GPU调用的GPU函数.</p>
<p>运行在GPU上的<code>global</code>函数称为kernel(内核函数), CUDA C扩展了C的语法, 允许程序员用C语言定义在GPU上运行的函数. 内核函数通过<code>__global__</code>限定符定义, 在GPU上执行的线程层次与数量通过&lt;&lt;&lt;…&gt;&gt;&gt;语法配置.下面是一个简单的kernel函数定义与调用的例子:</p>
<pre><code class="lang-c">// Kernel definition
__global__ void vecAdd(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}
int main()
{
    //...
    // Kernel invocation with N threads
    vecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C);
    //...
}</code></pre>
<p>host与device端的代码都是用与C语言语法相似的CUDA C编写, 后面会简要介绍CUDA C的语法. </p>
<h3 id="-block-thread-warp">线程层次模型 block, thread, warp</h3>
<p>CUDA GPU中, 基本的串行执行单位称为线程(thread), 一定数量的线程被组织为一个线程块(block), 线程块的尺寸与维度由程序员确定, 即可以通过一维与两维索引(threadIdx)来索引线程块中的线程. 由程序员确保一个线程块中的线程能够乱序执行. </p>
<p>一定数量的线程块又被组织为一个grid, 同样的, 也可以通过多维索引(blockIdx)来索引一个grid中的block. </p>
<p>之所以使用两级线程组织, 是为了支持多种并行方式, 即在block之间的任务级(task level)block内线程的数据级(data level)并行. 在一个线程块中的线程在执行时会被分配到同一个Stream Multiprocessor上, 因此能够较为方便的以较小的开销进行通信与同步. 即通过片上共享内存进行通信, 通过<code>_syncthreads()</code>函数进行同步等, 而不同的block之间没有内置的通信机制, 只能够通过全局显存进行通信.</p>
<p>在理论上, 同一个block内的线程之间可以执行完全不同的代码, 即通过threadIdx为索引到的各个线程分配不同的任务. 但实际的执行模型中, 还有warp这个概念, 一个warp是指一个block内线程号连续的一定数量的一束线程. 在截至目前的CUDA版本中, 一个warp有32个线程. GPU中的指令以warp为单位发射, 同一时刻, 一个warp中的线程总是执行相同的指令. 如果一个warp中的线程指令不同, 则warp中的每条指令都会被所有线程执行一遍. 后面会讲到, CUDA的SIMT(single instruction multi thread)模型, 其实仍然是SIMD的一种变种. </p>
<p>关于warp, 有两点结论, 第一是同一个warp内的线程(可以通过threadIdx % 32获得warp号)是不需要同步的, 因为它们在硬件层面强制同步, 程序员大可不必为属于同一个warp的两个线程设置同步机制, 第二是如果一个warp中的线程指令差异很大, 例如两个线程的程序完全不同或者线程有太多的条件控制跳转逻辑等. 就会非常影响执行效率. </p>
<p>需要注意的是, warp对程序员是透明的, 它并不是编程模型中的概念, 而是执行模型中的概念, 无视warp并不会影响程序的正确性, 而只是影响效率而已. 这点类似于传统CPU编程中cache的作用, cache对程序员也是透明的, 在C的模型中只有CPU与内存这两个概念, 并没有专门操作cache的机制, 然而, 如果代码不够cache-friendly, 会极大的影响程序速度. 反之, 如果程序对cache友好, 甚至可能会在多核环境下因为多核带来的更大cache而使程序达到超线性加速比. </p>
<h2 id="cuda-">CUDA 存储器模型</h2>
<p>下图为CUDA的内存模型示意图. 可以看出, CUDA模型中的内存分为GPU内部的片上存储器和片外显存. </p>
<center><img width=480 style='margin:20px' src="./image/CUDA_MEM_MODEL.png"></center>

<p>CUDA采用多级存储器模型, 每个线程拥有自己的寄存器(register)和私有的局部内存(local memory), 每个block拥有对block内的线程可见的共享内存(shared memory), 用于线程之间的数据同步. 所有的线程, 都可以对全局内存进行访问.</p>
<p>为了节约内存带宽, CUDA 之中还有特殊设计的纹理内存(texture memory)和常量内存(constant memory). 其中, 寄存器与共享内存是GPU上的片内存储器, 访存速度较快, 其他类型的存储器则位于片外的存储器上, 具有较高的访存延迟. 不过CUDA可以通过零开销的线程切换来隐藏延迟. </p>
<p>需要注意的一点是, 线程私有的局部内存(local memory)并不是片上内存, 而是在显存上分出的一块只对某个线程可见的内存, 因此, 对local memory的访问开销很大.</p>
<h3 id="-">寄存器与局部内存</h3>
<p>寄存器(register)是GPU的片上高速缓存, 执行单元可以以极低的延迟访问寄存器. 寄存器有很高的带宽. 寄存器数量虽然可观, 但会平均分给并行执行的线程, 因而当线程数较多时每个线程拥有的寄存器数量就非常有限了. </p>
<p>当寄存器数量不够, 比如线程定义了太多私有变量或者在线程内定义了大数组时, 变量就会被分配到local </p>
<p>对每个线程而言, 局部存储器(local memory)也是私有的. 当寄存器被消耗完, 线程的数据就会被存储在局部存储器中.  局部存储器并不是片上存储器, 而是位于GPU之外的显存上, 因此, 对局部存储器的访问速度很慢. 因此, CUDA程序设计时, 应对线程的私有变量大小进行预判, 不应为线程分配过多的私有变量, 应尽量避免因寄存器数量不够而将变量分配到局部内存上. 如前所述, local memory位于片外显存, 访问开销很大, 因此, 不应该分配过多线程或者在单个线程中定义太多私有变量. </p>
<h3 id="-">块内共享内存</h3>
<p>共享存储器(shared memory)也是GPU片内高速存储器, 它是一块可以白同一block中所有的线程访问的可读写存储器, 访问共享存储器的速度几乎和访问寄存器一样快, 是实现线程间通信的延迟最小的方法, 共享存储器可用于实现多种功能, 如用于保存共用的计数器, 或者block的公用结构. </p>
<p>共享存储器可以静态分配, 也可以动态分配, 如果动态分配, 则共享存储器的大小需要在kernel中用<code>extern</code>声明.</p>
<p>下面是一个通过共享存储器进行数组求和的程序例子:</p>
<pre><code class="lang-c++">__global__ void sumReduction(float *sum)
{
    extern __shared__ float cache[];
    int idx    = threadIdx.x;
    cache[idx] = 0;
    /*
     * ... calc cache[idx] for each thread
     */
    __syncthreads();
    int i=blockDim.x/2;//要求blockDim.x为2的幂
    while(i != 0)
    {
        if(idx&lt;i)
            cache[idx]+=cache[idx+i];
        __syncthreads(); //如果线程数小于32(一个warp), 则不必同步
        i/=2;
    }
    *sum=cache[0];
}</code></pre>
<h3 id="-">全局内存</h3>
<p>全局存储器(global memory)位于片外显存, 主机端/设备端均可以进行读写. 任意线程都能读写全局存储器的任意位置. 全局存储器能够提供很高的带宽, 但同时也有较高的访存延迟. </p>
<p>对全局存储器的访问, 可以通过CUDA提供的运行时API或驱动API来实现, 使用CUDA C的关键字<strong>device</strong>定义的变量也会分配到全局存储器. </p>
<p>常用的CPU-GPU互动方式就是, CPU分配显存, 然后调用kernel函数, kernel函数运行完成后, 再从显存copy数据到CPU内存. </p>
<h3 id="-">常量内存与纹理内存</h3>
<p>常量内存(constant memory)是只读的地址空间, 位于片外显存, 但拥有缓存加速. 常数存储器空间较小, 在CUDA程序中用于存储需要频繁访问的只读参数.用以节约带宽. </p>
<p>纹理存储器(texture)也是只读存储器, 主要就是用于图像编程当中的纹理這染等作用, 也可以称之为图像处理的专门单元所设置的一种存储器. 它主要存储数据的模式是以数组的形式存储在显存当中的. 这些数组包含了一维, 二维以及三维. 但是它所能声明的数组的大小要比常量存储器大的多, 而且也具有缓存加速的功能, 多被用于图像处理, 在查找表中也有着广泛的使用. 所以, 图像编程过程中经常的被用于数据量比较大的访问, 这些访问包含了对齐及非对齐的, 以及随机的数据. </p>
<h2 id="cuda-">CUDA硬件映射</h2>
<p>支持CUDA的GPU中, 一个具有完整的取指, 译码, 发射, 执行功能的处理单元被称为一个流多处理器(SM, Stream Multiprocessor), 下图为Kepler架构GPU的一个SM的框图. 每一个SM中有多个计算单元, 被称为流处理器(SP, Stream Processor), 每个SP中都包含浮点数与整数运算逻辑, 同时SM中还有大量双精度浮点数运算单元(DPU), 以及特殊的浮点数运算(如专门为计算平方根倒数运算)而设计的特殊浮点数运算单元(SFU). 不同架构的GPU中, 每个SM中的SP数量不同, Tesla架构中, 每个SM含有8个SP, Fermi架构中, 每个SM含有48个SP, Kepler架构中, 每个SM中含有192个SP.     </p>
<center><img width=640 style='margin:20px' src="./image/KEPLER_GPU.png"></center>

<p>在nvidia公司的商业宣传中, GPU往往被说成拥有数百个乃至上千个核, 这里的核通常指SP的数量, 而非SM的数量. 事实上, SP只是执行单元, 并不是完整的处理核心. 隶属同一SM的所有SP公用一套取指令与发射单元, 也公用一块共享存储器. </p>
<p>CUDA的kernel函数被配置为不同block并行执行, 同一个block中的线程需要进行通信与数据共享, 因此一个block会被映射到一个SM上执行, 而block中的每一个线程则被发射到一个SP上执行. 同一个SM中可以有多个活动线程块(active block)以隐藏延迟, 当一个block进行高延迟操作时, 另一个block可以占用GPU资源进行计算. </p>
<h2 id="cuda-">CUDA执行模型</h2>
<h2 id="cuda-">CUDA 新特性</h2>
<h2 id="thrust-">thrust库</h2>
<h2 id="cuda-profiler">CUDA profiler</h2>
<h2 id="cuda-">CUDA加速程序举例, 及加速比分析</h2>
<input type='hidden' id='markdowncodestyle' value='vs'>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
